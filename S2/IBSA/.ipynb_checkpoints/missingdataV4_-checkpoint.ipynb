{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67ea5a62-939b-4608-acbc-149252663e5b",
   "metadata": {},
   "source": [
    "## read data from files netatmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "b9cf5b9a-5cd2-45c1-a0b3-d837ccd70323",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#import tensorflow as tf\n",
    "#from tensorflow import keras\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "\n",
    "\n",
    "#!pip install wget \n",
    "import wget\n",
    "#wget.download('https://raw.githubusercontent.com/BorisMuzellec/MissingDataOT/master/utils.py')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils import *\n",
    "import torch\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "register_matplotlib_converters()\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.5)\n",
    "\n",
    "rcParams['figure.figsize'] = 22, 10\n",
    "\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "687e0074-3c00-4171-8591-f2f16fba2b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# supprimer d'abord les deux lignes dans le fichier d'export Neatatmo\n",
    "index_col=\"time\"\n",
    "data=pd.read_csv('dataCompletAvrilto18Juin.csv', sep=\";\", encoding = \"ISO-8859-1\", index_col=index_col)\n",
    "#df.to_csv('MCAR25.csv')\n",
    "# supprimer d'abord les deux lignes dans le fichier d'export Neatatmo\n",
    "index_col=\"time\"\n",
    "p=\"5.csv\"\n",
    "\n",
    "df=pd.read_csv('MCAR'+p, sep=\",\", encoding = \"ISO-8859-1\", index_col=index_col)\n",
    "mask=pd.read_csv('mask'+p, sep=\",\", encoding = \"ISO-8859-1\", index_col=index_col)\n",
    "mask=mask.values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411e08af-6601-4055-8dc6-8599a6d09eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_kalman=pd.read_csv('MCAR'+p, sep=\",\", encoding = \"ISO-8859-1\")\n",
    "X_kalmanArimaImputed=pd.read_csv('kalmanArima_TRUE_MCAR'+p, sep=\",\", encoding = \"ISO-8859-1\")\n",
    "X_kalmanStructTsImputed=pd.read_csv('kalmanStructTS_TRUE_MCAR'+p, sep=\",\", encoding = \"ISO-8859-1\")\n",
    "X_kalmanArimaImputed=X_kalmanArimaImputed.set_index('time')\n",
    "X_kalmanStructTsImputed=X_kalmanStructTsImputed.set_index('time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "1e97bf8f-31d1-40a6-8032-c7d02ebb4eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix the seed ------------------------------------------------------\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "99a4b44a-ee14-4ccf-8541-f169481388d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.copy()\n",
    "X = X.drop([\"activity\"], axis=1)\n",
    "X = X.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "497d1c55-e135-4ea9-b627-cc594fa998f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "datascaler=scaler.fit(X)\n",
    "X= datascaler.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b943a2d-34c3-4731-8932-3bb13bcde046",
   "metadata": {},
   "source": [
    "## Time Series Imputation Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "1d111f6a-e495-4837-8577-20289d323859",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Forward Fill\n",
    "# Impute airquality DataFrame with ffill method\n",
    "\n",
    "### Forward Fill\n",
    "# Impute airquality DataFrame with ffill method\n",
    "import numpy as np\n",
    "from sklearn.impute import KNNImputer\n",
    "X1 = df.copy()\n",
    "# add time \"timpstame\" as variable \n",
    "X1[\"time\"]=X1.index\n",
    "k=2\n",
    "imputer = KNNImputer(n_neighbors=k)\n",
    "KNNimputed = imputer.fit_transform(X1)\n",
    "KNNimputed=KNNimputed[:,0:-1].copy()\n",
    "KNNimputed= pd.DataFrame(data=KNNimputed, columns=df.columns)\n",
    "KNNimputed.index = df.index\n",
    "\n",
    "ffill_imputed = df.copy(deep=True)\n",
    "ffill_imputed.fillna(method='ffill',inplace=True)\n",
    "ffill_imputed.fillna(method='bfill',inplace=True)\n",
    "\n",
    "bfill_imputed = df.copy(deep=True)\n",
    "bfill_imputed.fillna(method='bfill',inplace=True)\n",
    "bfill_imputed.fillna(method='ffill',inplace=True)\n",
    "\n",
    "quadratic_imput = df.copy(deep=True)\n",
    "quadratic_imput.interpolate(method='quadratic', inplace=True)\n",
    "quadratic_imput.fillna(method='ffill',inplace=True)\n",
    "quadratic_imput.fillna(method='bfill',inplace=True)\n",
    "\n",
    "\n",
    "nearest_imput = df.copy(deep=True)\n",
    "nearest_imput.interpolate(method='nearest', inplace=True)\n",
    "nearest_imput.fillna(method='ffill',inplace=True)\n",
    "nearest_imput.fillna(method='bfill',inplace=True)\n",
    "\n",
    "\n",
    "linear_imput=df.copy(deep=True)\n",
    "linear_imput.interpolate(method='linear', inplace=True)\n",
    "linear_imput.fillna(method='ffill',inplace=True)\n",
    "linear_imput.fillna(method='bfill',inplace=True)\n",
    "\n",
    "poly_imput=df.copy(deep=True)\n",
    "poly_imput= poly_imput.interpolate(method='polynomial', order=3)\n",
    "poly_imput.fillna(method='ffill',inplace=True)\n",
    "poly_imput.fillna(method='bfill',inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ead8ac-2922-44ca-a54c-a4e0d39ff178",
   "metadata": {},
   "source": [
    "# Save dataFrame Imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "ac5a89d9-9bc7-496a-93b8-dfec25c3c598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Back_fill5.csv <class 'pandas.core.frame.DataFrame'>\n",
      "Forward_fill5.csv <class 'pandas.core.frame.DataFrame'>\n",
      "Linear_Interpolation5.csv <class 'pandas.core.frame.DataFrame'>\n",
      "Quadratic_Interpolation5.csv <class 'pandas.core.frame.DataFrame'>\n",
      "Nearest_imput5.csv <class 'pandas.core.frame.DataFrame'>\n",
      "polynomial_interpolation5.csv <class 'pandas.core.frame.DataFrame'>\n",
      "KNN5.csv <class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary of interpolations\n",
    "interpolations = {'Back_fill':bfill_imputed, 'Forward_fill':ffill_imputed,\n",
    "                  'Linear_Interpolation': linear_imput, 'Quadratic_Interpolation': quadratic_imput,\"Nearest_imput\":nearest_imput, \"polynomial_interpolation\":poly_imput, 'KNN': KNNimputed}\n",
    "# enregistrer les données imputéés par chaque méthode dans le dossier dataImputed\n",
    "for df_key in  interpolations:\n",
    "    print(df_key+p,type(interpolations[df_key]))\n",
    "    #interpolations[df_key].to_csv('dataImputed/'+df_key+p)\n",
    "            \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "8cb8163d-738b-4e4b-980c-cb8f948f626c",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_imput.to_csv('dataImputed/data0.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "35bc432a-cd8c-47aa-bd8d-be238664b1d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  19.89999998,   55.9999999 ,  647.00000059,   31.99999998,\n",
       "        1017.5       ],\n",
       "       [  19.89999998,   55.9999999 ,  601.99999884,   31.99999998,\n",
       "        1017.5       ],\n",
       "       [  19.89999998,   55.9999999 ,  608.99999882,   31.99999998,\n",
       "        1017.6       ],\n",
       "       ...,\n",
       "       [  24.19999975,   62.00000027,  637.99999991,   37.99999999,\n",
       "        1014.50000005],\n",
       "       [  24.19999975,   62.00000027,  648.00000011,   37.99999999,\n",
       "        1014.30000005],\n",
       "       [  24.19999975,   62.00000027,  669.00000004,   37.99999999,\n",
       "        1014.19999994]])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "datascaler.inverse_transform(quadratic_imput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a74a991-0ff2-41ce-803e-72ce37fb5cc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "e057558c-9448-4091-a761-4f0be2a47cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.impute import KNNImputer\n",
    "X1 = df.copy()\n",
    "k=1100\n",
    "imputer = KNNImputer(n_neighbors=k)\n",
    "KNNimputed = imputer.fit_transform(X1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d80eab-c05e-423d-a305-7e825a12130f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importation de la bibiothèque RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# construire un model random forest\n",
    "# Instanciation du modèle\n",
    "rf_model=RandomForestClassifier(max_features='log2', n_estimators= 300, max_depth=500, criterion='entropy') \n",
    "# entrainement du model\n",
    "rf_model.fit(X_train,y_train)\n",
    "# afficher le score du modele sur les données d'entrainement\n",
    "rf_model.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71db2fc-ada9-454a-9079-027e8022c881",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "pd.DataFrame(confusion_matrix(y_test, rf_model.predict(X_test)),\n",
    "             index = [\"Present_data\", \"Abscent_data\"],\n",
    "             columns = [\"Present_predit\", \"Abscent_predit\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
